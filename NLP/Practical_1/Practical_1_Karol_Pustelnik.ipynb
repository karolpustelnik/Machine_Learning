{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practical_1_Karol_Pustelnik",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Practical 1 - Karol Pustelnik 446518**"
      ],
      "metadata": {
        "id": "Oj_G4NGM4-X6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Practical 1\n",
        "\n",
        "Greatly inspired by Stanford CS224 2019 class.\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "\n",
        "import pprint\n",
        "from turtle import window_width\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.test.utils import datapath\n",
        "import random\n",
        "import nltk\n",
        "\n",
        "nltk.download('reuters')\n",
        "nltk.download('pl196x')\n",
        "import random\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from nltk.corpus import reuters\n",
        "from nltk.corpus.reader import pl196x\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "\n",
        "START_TOKEN = '<START>'\n",
        "END_TOKEN = '<END>'\n",
        "\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCFSqhHl0N-k",
        "outputId": "645915fa-0ab0-4f8f-f86d-9e8b9f7e4d37"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]   Package pl196x is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim --upgrade"
      ],
      "metadata": {
        "id": "Cv2LEQfVnN4F",
        "outputId": "3863fb63-8091-4c51-d9a8-e4c7462dc40d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 71.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.1.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gensim"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim"
      ],
      "metadata": {
        "id": "QeVanxhAzX7M"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gensim.__version__)"
      ],
      "metadata": {
        "id": "d766oF2Uw1IV",
        "outputId": "e39d45be-c014-48b9-e41d-7d1db6d70959",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **a) Implement `distinct words` function**"
      ],
      "metadata": {
        "id": "IYyhGPnlz_A9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "# TODO: a)\n",
        "def distinct_words(corpus):\n",
        "    \"\"\" Determine a list of distinct words for the corpus.\n",
        "        Params:\n",
        "            corpus (list of list of strings): corpus of documents\n",
        "        Return:\n",
        "            corpus_words (list of strings): list of distinct words across the \n",
        "            corpus, sorted (using python 'sorted' function)\n",
        "            num_corpus_words (integer): number of distinct words across the \n",
        "            corpus\n",
        "    \"\"\"\n",
        "    corpus_words = []\n",
        "    num_corpus_words = -1\n",
        "    \n",
        "    # ------------------\n",
        "    # Write your implementation here.\n",
        "    for document in corpus:\n",
        "        for word in document:\n",
        "            if word not in corpus_words:\n",
        "                corpus_words.append(word)\n",
        "    corpus_words = sorted(corpus_words)\n",
        "    num_corpus_words = len(corpus_words)\n",
        "    # ------------------\n",
        "\n",
        "    return corpus_words, num_corpus_words\n",
        "\n",
        "\n",
        "# ---------------------\n",
        "# Run this sanity check\n",
        "# Note that this not an exhaustive check for correctness.\n",
        "# ---------------------\n",
        "\n",
        "# Define toy corpus\n",
        "test_corpus = [\"START Ala miec kot i pies END\".split(\" \"),\n",
        "               \"START Ala lubic kot END\".split(\" \")]     \n",
        "test_corpus_words, num_corpus_words = distinct_words(test_corpus)\n",
        "\n",
        "# Correct answers\n",
        "ans_test_corpus_words = sorted(list(set([\n",
        "    'Ala', 'END', 'START', 'i', 'kot', 'lubic', 'miec', 'pies'])))\n",
        "ans_num_corpus_words = len(ans_test_corpus_words)\n",
        "\n",
        "# Test correct number of words\n",
        "assert(num_corpus_words == ans_num_corpus_words), \"Incorrect number of distinct words. Correct: {}. Yours: {}\".format(ans_num_corpus_words, num_corpus_words)\n",
        "\n",
        "# Test correct words\n",
        "assert (test_corpus_words == ans_test_corpus_words), \"Incorrect corpus_words.\\nCorrect: {}\\nYours:   {}\".format(str(ans_test_corpus_words), str(test_corpus_words))\n",
        "\n",
        "# Print Success\n",
        "print (\"-\" * 80)\n",
        "print(\"Passed All Tests!\")\n",
        "print (\"-\" * 80)\n"
      ],
      "metadata": {
        "id": "IErIRvO3y7j0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c37945ee-6153-4d6c-b87f-72921516cc2a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Passed All Tests!\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **b) Implement `compute co occurrence matrix` function**"
      ],
      "metadata": {
        "id": "SFI-e5Zv0Cyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "# TODO: b)\n",
        "def compute_co_occurrence_matrix(corpus, window_size=4):\n",
        "    \"\"\" Compute co-occurrence matrix for the given corpus and window_size (default of 4).\n",
        "    \n",
        "        Note: Each word in a document should be at the center of a window.\n",
        "            Words near edges will have a smaller number of co-occurring words.\n",
        "              \n",
        "              For example, if we take the document \"START All that glitters is not gold END\" with window size of 4,\n",
        "              \"All\" will co-occur with \"START\", \"that\", \"glitters\", \"is\", and \"not\".\n",
        "    \n",
        "        Params:\n",
        "            corpus (list of list of strings): corpus of documents\n",
        "            window_size (int): size of context window\n",
        "        Return:\n",
        "            M (numpy matrix of shape (number of corpus words, number of corpus words)): \n",
        "                Co-occurence matrix of word counts. \n",
        "                The ordering of the words in the rows/columns should be the \n",
        "                same as the ordering of the words given by the distinct_words \n",
        "                function.\n",
        "            word2Ind (dict): dictionary that maps word to index \n",
        "                (i.e. row/column number) for matrix M.\n",
        "    \"\"\"\n",
        "    words, num_words = distinct_words(corpus)\n",
        "    M = np.zeros((num_words, num_words))\n",
        "    word2Ind = {}\n",
        "    print(M)\n",
        "    # ------------------\n",
        "    # Write your implementation here.\n",
        "    for i, word1 in enumerate(words):\n",
        "        word2Ind.update({word1: i})\n",
        "    for document in corpus:\n",
        "            for word1 in document:\n",
        "                for word2 in document:\n",
        "\n",
        "                    if abs(document.index(word2) - document.index(word1))< window_size+1 and word2 !=word1 :\n",
        "                        M[word2Ind[word1],word2Ind[word2]] +=1\n",
        "    return M, word2Ind"
      ],
      "metadata": {
        "id": "-u5T12Sk0UMp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------\n",
        "# Run this sanity check\n",
        "# Note that this is not an exhaustive check for correctness.\n",
        "# ---------------------\n",
        "\n",
        "# Define toy corpus and get student's co-occurrence matrix\n",
        "test_corpus = [\"START Ala miec kot i pies END\".split(\" \"),\n",
        "               \"START Ala lubic kot END\".split(\" \")]     \n",
        "M_test, word2Ind_test = compute_co_occurrence_matrix(\n",
        "    test_corpus, window_size=1)\n",
        "\n",
        "# Correct M and word2Ind\n",
        "M_test_ans = np.array([\n",
        "    [0., 0., 2., 0., 0., 1., 1., 0.],\n",
        "    [0., 0., 0., 0., 1., 0., 0., 1.],\n",
        "    [2., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 1., 0., 0., 1.],\n",
        "    [0., 1., 0., 1., 0., 1., 1., 0.],\n",
        "    [1., 0., 0., 0., 1., 0., 0., 0.],\n",
        "    [1., 0., 0., 0., 1., 0., 0., 0.],\n",
        "    [0., 1., 0., 1., 0., 0., 0., 0.]\n",
        "])\n",
        "\n",
        "word2Ind_ans = {\n",
        "    'Ala': 0, 'END': 1, 'START': 2, 'i': 3, 'kot': 4, 'lubic': 5, 'miec': 6,\n",
        "    'pies': 7}\n",
        "\n",
        "# Test correct word2Ind\n",
        "assert (word2Ind_ans == word2Ind_test), \"Your word2Ind is incorrect:\\nCorrect: {}\\nYours: {}\".format(word2Ind_ans, word2Ind_test)\n",
        "\n",
        "# Test correct M shape\n",
        "assert (M_test.shape == M_test_ans.shape), \"M matrix has incorrect shape.\\nCorrect: {}\\nYours: {}\".format(M_test.shape, M_test_ans.shape)\n",
        "\n",
        "# Test correct M values\n",
        "for w1 in word2Ind_ans.keys():\n",
        "    idx1 = word2Ind_ans[w1]\n",
        "    for w2 in word2Ind_ans.keys():\n",
        "        idx2 = word2Ind_ans[w2]\n",
        "        student = M_test[idx1, idx2]\n",
        "        correct = M_test_ans[idx1, idx2]\n",
        "        if student != correct:\n",
        "            print(\"Correct M:\")\n",
        "            print(M_test_ans)\n",
        "            print(\"Your M: \")\n",
        "            print(M_test)\n",
        "            raise AssertionError(\"Incorrect count at index ({}, {})=({}, {}) in matrix M. Yours has {} but should have {}.\".format(idx1, idx2, w1, w2, student, correct))\n",
        "\n",
        "# Print Success\n",
        "print (\"-\" * 80)\n",
        "print(\"Passed All Tests!\")\n",
        "print (\"-\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM2kaEIP0oNG",
        "outputId": "787c8e65-861b-42da-b002-b1884bb045eb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "--------------------------------------------------------------------------------\n",
            "Passed All Tests!\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **c) Implement `reduce to k dim` function**"
      ],
      "metadata": {
        "id": "1K9nQAkP0LHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "# TODO: c)\n",
        "def reduce_to_k_dim(M, k=2):\n",
        "    \"\"\" Reduce a co-occurence count matrix of dimensionality\n",
        "        (num_corpus_words, num_corpus_words)\n",
        "        to a matrix of dimensionality (num_corpus_words, k) using the following\n",
        "         SVD function from Scikit-Learn:\n",
        "            - http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html\n",
        "\n",
        "        Params:\n",
        "            M (numpy matrix of shape (number of corpus words, number \n",
        "                of corpus words)): co-occurence matrix of word counts\n",
        "            k (int): embedding size of each word after dimension reduction\n",
        "        Return:\n",
        "            M_reduced (numpy matrix of shape (number of corpus words, k)):\n",
        "            matrix of k-dimensioal word embeddings.\n",
        "            In terms of the SVD from math class, this actually returns U * S\n",
        "    \"\"\"\n",
        "    n_iters = 10     # Use this parameter in your call to `TruncatedSVD`\n",
        "    M_reduced = None\n",
        "    print(\"Running Truncated SVD over %i words...\" % (M.shape[0]))\n",
        "\n",
        "    # ------------------\n",
        "    svd = sklearn.decomposition.TruncatedSVD(n_components = k, n_iter = n_iters)\n",
        "    svd.fit(M)\n",
        "    M_reduced = svd.transform(M)\n",
        "    # ------------------\n",
        "\n",
        "    print(\"Done.\")\n",
        "    return M_reduced\n",
        "\n",
        "# ---------------------\n",
        "# Run this sanity check\n",
        "# Note that this not an exhaustive check for correctness \n",
        "# In fact we only check that your M_reduced has the right dimensions.\n",
        "# ---------------------\n",
        "\n",
        "# Define toy corpus and run student code\n",
        "test_corpus = [\"START Ala miec kot i pies END\".split(\" \"),\n",
        "               \"START Ala lubic kot END\".split(\" \")]  \n",
        "M_test, word2Ind_test = compute_co_occurrence_matrix(test_corpus, window_size=1)\n",
        "M_test_reduced = reduce_to_k_dim(M_test, k=2)\n",
        "\n",
        "# Test proper dimensions\n",
        "assert (M_test_reduced.shape[0] == 8), \"M_reduced has {} rows; should have {}\".format(M_test_reduced.shape[0], 8)\n",
        "assert (M_test_reduced.shape[1] == 2), \"M_reduced has {} columns; should have {}\".format(M_test_reduced.shape[1], 2)\n",
        "\n",
        "# Print Success\n",
        "print (\"-\" * 80)\n",
        "print(\"Passed All Tests!\")\n",
        "print (\"-\" * 80)\n",
        "\n",
        "#################################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV_bPbvm0pBo",
        "outputId": "48ae1fcc-056a-4232-d638-a667c348d80a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "Running Truncated SVD over 8 words...\n",
            "Done.\n",
            "--------------------------------------------------------------------------------\n",
            "Passed All Tests!\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **d) Implement `plot embeddings` function**"
      ],
      "metadata": {
        "id": "scyI7Sy30POr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: d)\n",
        "def plot_embeddings(M_reduced, word2Ind, words):\n",
        "    \"\"\" Plot in a scatterplot the embeddings of the words specified \n",
        "        in the list \"words\".\n",
        "        NOTE: do not plot all the words listed in M_reduced / word2Ind.\n",
        "        Include a label next to each point.\n",
        "        \n",
        "        Params:\n",
        "            M_reduced (numpy matrix of shape (number of unique words in the\n",
        "            corpus , k)): matrix of k-dimensioal word embeddings\n",
        "            word2Ind (dict): dictionary that maps word to indices for matrix M\n",
        "            words (list of strings): words whose embeddings we want to\n",
        "            visualize\n",
        "    \"\"\"\n",
        "\n",
        "    # ------------------\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for word in words:\n",
        "        w_index = word2Ind[word]\n",
        "        vector = M_reduced[w_index,:]\n",
        "        xs.append(vector[0])\n",
        "        ys.append(vector[1])\n",
        "    plt.scatter(xs,ys)\n",
        "    for i,t in enumerate(zip(xs,ys)):\n",
        "\n",
        "        label = words[i]\n",
        "\n",
        "        plt.annotate(label, # this is the text\n",
        "                 t, # these are the coordinates to position the label\n",
        "                 textcoords=\"offset points\", # how to position the text\n",
        "                 xytext=(0,10), # distance from text to points (x,y)\n",
        "                 ha='center')\n",
        "    plt.show()\n",
        "\n",
        "    # ------------------#\n",
        "\n",
        "# ---------------------\n",
        "# Run this sanity check\n",
        "# Note that this not an exhaustive check for correctness.\n",
        "# The plot produced should look like the \"test solution plot\" depicted below. \n",
        "# ---------------------\n",
        "\n",
        "print (\"-\" * 80)\n",
        "print (\"Outputted Plot:\")\n",
        "\n",
        "M_reduced_plot_test = np.array([[1, 1], [-1, -1], [1, -1], [-1, 1], [0, 0]])\n",
        "word2Ind_plot_test = {\n",
        "    'test1': 0, 'test2': 1, 'test3': 2, 'test4': 3, 'test5': 4}\n",
        "words = ['test1', 'test2', 'test3', 'test4', 'test5']\n",
        "plot_embeddings(M_reduced_plot_test, word2Ind_plot_test, words)\n",
        "\n",
        "print (\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "jTrufVji0tB_",
        "outputId": "8adc46fe-93fd-455f-9189-55577690de27"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Outputted Plot:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **e) Co-Occurrence Plot Analysis**"
      ],
      "metadata": {
        "id": "GKaYBwo50UlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "# TODO: e)\n",
        "# -----------------------------\n",
        "# Run This Cell to Produce Your Plot\n",
        "# ------------------------------\n",
        "\n",
        "def read_corpus_pl():\n",
        "    \"\"\" Read files from the specified Reuter's category.\n",
        "        Params:\n",
        "            category (string): category name\n",
        "        Return:\n",
        "            list of lists, with words from each of the processed files\n",
        "    \"\"\"\n",
        "    pl196x_dir = nltk.data.find('corpora/pl196x')\n",
        "    pl = pl196x.Pl196xCorpusReader(\n",
        "        pl196x_dir, r'.*\\.xml', textids='textids.txt',cat_file=\"cats.txt\")\n",
        "    tsents = pl.tagged_sents(fileids=pl.fileids(),categories='cats.txt')[:5000]\n",
        "\n",
        "    return [[START_TOKEN] + [\n",
        "        w[0].lower() for w in list(sent)] + [END_TOKEN] for sent in tsents]\n",
        "\n",
        "\n",
        "def plot_unnormalized(corpus, words):\n",
        "    M_co_occurrence, word2Ind_co_occurrence = compute_co_occurrence_matrix(\n",
        "        corpus)\n",
        "    M_reduced_co_occurrence = reduce_to_k_dim(M_co_occurrence, k=2)\n",
        "    plot_embeddings(M_reduced_co_occurrence, word2Ind_co_occurrence, words)\n",
        "\n",
        "\n",
        "def plot_normalized(corpus, words):\n",
        "    M_co_occurrence, word2Ind_co_occurrence = compute_co_occurrence_matrix(\n",
        "        corpus)\n",
        "    M_reduced_co_occurrence = reduce_to_k_dim(M_co_occurrence, k=2)\n",
        "    # Rescale (normalize) the rows to make them each of unit-length\n",
        "    M_lengths = np.linalg.norm(M_reduced_co_occurrence, axis=1)\n",
        "    M_normalized = M_reduced_co_occurrence / M_lengths[:, np.newaxis] # broadcasting\n",
        "    plot_embeddings(M_normalized, word2Ind_co_occurrence, words)\n",
        "\n",
        "pl_corpus = read_corpus_pl()\n",
        "words = [\n",
        "    \"sztuka\", \"śpiewaczka\", \"literatura\", \"poeta\", \"obywatel\"]\n",
        "\n",
        "plot_normalized(pl_corpus, words)\n",
        "plot_unnormalized(pl_corpus, words)\n",
        "\n",
        "\n",
        "#################################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "3JpRXjmx0wHM",
        "outputId": "2e24ce2a-fa61-4ad3-9685-47d910af8749"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "Running Truncated SVD over 22957 words...\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEBCAYAAABmCeILAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3gU9b3H8fcXgjGCcvfCxYZWjWIiia54WkRR0WC1ghZvRQsHlUM99KKnPKJWpWhPUdTe1FZsFeyxFRstcryUIpeCR0Q2ECWoEaQIJKgol4oGCfA9f+wkLnEzSdhNNoHP63n2ycxvfrPz3cluPpmZ3d+auyMiIlKXNukuQEREWjYFhYiIhFJQiIhIKAWFiIiEUlCIiEgoBYWIiIRSUIhISplZhpnNN7Pj012LpIaCQkRSbQLwS3d/u64OZjbWzL7bjDXVVccCM4uku46WLiPdBYjI/sXd72pAn981Ry2SGjqiEJGUMLP2Zva8mb1uZqVmdrmZrTWze8xshZm9ZmbHBH0nmtmPg+mvmdnfzKzYzBaZ2fFm1tbM/mkxncxst5mdEfRfaGbHmll/M1tsZsvN7BUzywmWtzWze4Ma3jCz75tZxMxKgtsKM/Natbcxs2lmdlcwPzOoZ6WZjWnePdny6IhCRFJlCFDh7hcAmFlH4G5gm7vnBaeafglcWGu9qcBYd19lZqcBD7n72WZWBvQF+gDLgIFmtgToHfQ9DBjo7rvMbDDw38C3gTFANpAfLOvi7puB/KCuKcDf4rafATwBlLr7z4K20e6+2cyygKVm9rS7f5zCfdWqKChEJFVWAPeZ2d3Ac+6+yMwA/hws/zPwi/gVzKwD8A3gL0FfgMzg5yLgDGJB8XPgOuAfwNJgeUdgupkdCzjQLmgfDPzO3XcBBCFRvb3LgZOB8+LKeBh4Ki4kAH5gZhcH072BY4EDNih06klEUsLd3yH2R3gFcJeZ3V69KL5brdXaAFvdPT/udkKwbCEwEOgPvAB0AgYRCxCAO4H57p4LfAs4OKw+M8sFJgJXuPvuuEWvAGeZ2cFBv0HEwubr7t4PWF7ffe/vFBQikhJm1gP4zN3/B5hCLDQALo/7uTh+HXf/F/BPM7s0uA8zs37B4teIHW3scfcdQAnwH8QCBGJHFOXB9Ki4u50D/IeZZQT32cXMOhE7ovmuu2+qVfofiAXRU8E6HYEt7v5Z8Bbff2v0ztjPWGscZrxbt26enZ2d7jJEJM62bdsoL4/93TYzjj76aNasWUPnzp3517/+hZnRp08fDj74YCoqKmjTpg1HHnkkn3/+OevWraOqqgp3p3PnzvTo0QOAsrIyOnToQM+ePdm8eTPr1q2jX79+mBnbt29n7dq1tGnTho4dO7J582by8vJwdzZs2FCzzW7dutG2bVvWrVtHZmZmTb19+/alrKyMXr160b59eyoqKtixYwfZ2dm8++677Ny5k8zMTHbv3k2PHj049NBD07JfU6m4uPgjd+/e2PVa5TWK7OxsotFoussQkXpUv1a7deuW7lIEMLP39mU9nXoSEZFQrfKIQkRah7Vr16a7BEkBHVGIiEgoBYWIiIRSUIiISKiUBIWZDTGzMjNbbWYTEizPNLMZwfIlZpZda/nRZra9euwXEZG6zFxezoDJ8+gz4XkGTJ7HzOXl9a8kSUk6KMysLfAgcD6xcVmuNLO+tbpdQ+wDLMcQ+wj/3bWW3w+8mGwtIrJ/m7m8nJufWUH51kocKN9ayc3PrFBYNLFUHFH0B1a7+xp33wk8CQyt1WcoMD2YLgLOsWBgFzMbBvwTWJmCWkRkPzZldhmVVbv3aqus2s2U2WVpqujAkIqg6Amsj5vfELQl7BMM1LUN6BoMCHYT8NP6NmJmY8wsambRTZtqfwJfRA4EFVsrG9UuqZHui9kTgV+4+/b6Orr7VHePuHuke/dGfwJdRPYDPTplNapdUiMVQVFObBjear34YqCuL/WJG3TrY+A04B4zWwv8CLjFzMaloCYR2Q+NL8whq13bvdqy2rVlfGFOmio6MKTik9lLgWPNrA+xQLgC+E6tPrOAkcRGjhwOzPPYaIQDqzuY2URgu7s/kIKaRGQ/NKwgdlZ7yuwyKrZW0qNTFuMLc2rapWkkHRTBN0iNA2YDbYFH3X2lmU0Cou4+i9gwvn80s9XAZmJhIiLSaMMKeioYmlmrHGY8Eom4Ro8VEWkcMyt290hj10v3xWwREWnhFBQiIhJKQSEiIqEUFCIiEkpBISIioRQUIiISSkEhIiKhFBQiIhJKQSEiIqEUFCIiEkpBISIioRQUIiISSkEhItKCTJs2jYqKinSXsRcFhYhIC6KgEBHZT61du5bjjz+eESNGcMIJJzB8+HA+++wz5s6dS0FBAXl5eYwePZrPP/8cgOLiYs4880xOOeUUCgsL2bhxI0VFRUSjUUaMGEF+fj6VlZVMmjSJU089ldzcXMaMGUM6vhpCQSEikiJlZWVcf/31vPXWWxx22GHcf//9jBo1ihkzZrBixQp27drFb3/7W6qqqvj+979PUVERxcXFjB49mltvvZXhw4cTiUR44oknKCkpISsri3HjxrF06VJKS0uprKzkueeea/bHpaAQEUmR3r17M2DAAACuuuoq5s6dS58+fTjuuOMAGDlyJAsXLqSsrIzS0lLOPfdc8vPzueuuu9iwYUPC+5w/fz6nnXYaeXl5zJs3j5UrVzbb46mWiu/MFhERwMz2mu/UqRMff/zxl/q5OyeeeCKLFy8Ovb8dO3Zw/fXXE41G6d27NxMnTmTHjh0prbkhdEQhIpIi69atq/nj/6c//YlIJMLatWtZvXo1AH/84x8588wzycnJYdOmTTV9q6qqao4UDj30UD755BOAmlDo1q0b27dvp6ioqLkfEqCgEBFJmZycHB588EFOOOEEtmzZwg033MBjjz3GpZdeSl5eHm3atGHs2LEcdNBBFBUVcdNNN9GvXz/y8/N55ZVXABg1ahRjx44lPz+fzMxMrrvuOnJzcyksLOTUU09Ny+OydFxBT1YkEvFoNJruMkREaqxdu5YLL7yQ0tLSdJdSJzMrdvdIY9fTEYWIiIRKSVCY2RAzKzOz1WY2IcHyTDObESxfYmbZQfu5ZlZsZiuCn2enoh4RkeaWnZ3doo8mkpF0UJhZW+BB4HygL3ClmfWt1e0aYIu7HwP8Arg7aP8I+Ja75wEjgT8mW4+IiKRWKo4o+gOr3X2Nu+8EngSG1uozFJgeTBcB55iZuftyd6/+rPpKIMvMMlNQk4iIpEgqgqInsD5ufkPQlrCPu+8CtgFda/X5NrDM3T9PtBEzG2NmUTOLbtq0KQVli4g0rbVr15Kbm9ss22roGFFmNs3MhjfmvlvExWwzO5HY6aj/qKuPu09194i7R7p37958xYmINIGZy8sZMHkefSY8z4DJ85i5vDyp+2vKwQRTERTlQO+4+V5BW8I+ZpYBdAQ+DuZ7AX8Fvuvu76agHhGRtLj//vvJzc0lNzeXX/7ylwDs2rXrSwMFTnr4Ka6+4lLKt1biwOrlr3D1lZcy/p6HufHGGwH41a9+xVe/+lUA1qxZUzM0SKJBAhMNJpho0MF9lYqgWAoca2Z9zOwg4ApgVq0+s4hdrAYYDsxzdzezTsDzwAR3/78U1CIikhbFxcU89thjLFmyhFdffZVHHnmELVu2fGmgwIceeoi/be7Kjo/Ws/uzbQBsX/ESWbmDWbCtK4sWLQJg0aJFdO3alfLychYtWsQZZ5wBkHCQwNqDCWZkZCQcdHBfJR0UwTWHccBs4C3gKXdfaWaTzOyioNsfgK5mthq4Eah+C+044BjgdjMrCW6HJ1uTiEhze/nll7n44otp3749HTp04JJLLmHRokVfGijw5ZdfZuO2HXQ48Sw+XTmfPTu283nF22R9NcJHu7PYvn07n3zyCevXr+c73/kOCxcuZNGiRQwcOBBo2CCBjRl0sCFSMiigu78AvFCr7fa46R3ApQnWuwu4KxU1iIi0RLUHCjQzenTKoipvMJuenoRlHET7nAFYm7b06JTF8d/4Bo899hg5OTkMHDiQRx99lMWLF3Pfffc1eJDAugYdrF1LQ7WIi9kiIq3dwIEDmTlzJp999hmffvopf/3rXxk4cOCXBgo8/fTTGV+Yw6FdDqdthy5se+VJOuSdS1a7towvjIXDvffeyxlnnEFBQQHz588nMzOTjh07hg4SGD+YYNigg/tCw4yLiKTAySefzKhRo+jfvz8A1157LZ07d64ZKHD06NH07duX733vexxyyCEA3LT6PNb+o4jsY45jfGEOwwp68u5hA1m/fj1nnHEGbdu2pXfv3hx//PFAbNjy6kECjzzyyL0GCaweTDArK4vFixdTVFTED37wA7Zt28auXbv40Y9+tM+PTYMCioikybhx4ygoKOCaa65plu3t66CAOqIQEUmDU045hfbt23Pfffelu5R6KShERNKguLg43SU0mC5mi4hIKAWFiIiEUlCIiEgoXaMQEWmBZi4vZ8rsMiq2VtKjU1bN22fTQUEhItLCzFxezs3PrKCyajcA5VsrufmZFQBpCQudehIRSbEOHToAUFFRwfDhsa9+KCkp4YUXXghbrcaU2WU1IVGtsmo3U2aX1cxv3bqVhx56KEUVh1NQiIg0kR49etQMs9GYoKjYWgmA79mdsB32PSiCr69uFAWFiEgTqf6Gu507d3L77bczY8YM8vPzmTFjBp9++imjR4+mf//+FBQU8OyzzwKxLyDaNutnvP/nW/jgyVvZs7OSD568hY3TfsiH075f02/ChAm8++675OfnM378eBYsWMCFF15Ys+1x48Yxbdo0ALKzs7npppsATgAuNbPrzGypmb1uZk+b2SFhj0PXKEREmthBBx3EpEmTiEajPPDAAwDccsstnH322Tz66KNs3bqV/v37M3jwYADafPxPjr761+zMOATfs5vuF/+E9h0O5eazevJfYy7moosuYvLkyZSWllJSUgLAggULQmvo2rUrwFvu/qSZdXX3RwDM7C7gGuA3da2rIwoRkTT4+9//zuTJk8nPz2fQoEHs2LGDdevWAfCtbw7hnhHfoGenLMydqlefoPLJG7j/xqspLy/ngw8+aPT2Lr/88vjZXDNbZGYrgBHAiWHr6ohCRCQN3J2nn36anJycvdqXLFlC+/btGVbQk2EFPZk2bRovrsvkfxa+Qbt27cjOzk74HRQZGRns2bOnZr52n/bt28fPTgOGufvrZjYKGBRWq44oRESaQfz3RQAUFhbym9/8huoRvJcvX55wvW3btnH44YfTrl075s+fz3vvvZfw/r7yla/w5ptv8vnnn7N161bmzp0bWg6w0czaETuiCKWgEBFpBmeddRZvvvlmzcXs2267jaqqKk466SROPPFEbrvttoTrjRgxgmg0Sl5eHo8//njNd1N07dqVAQMGkJuby/jx4+nduzeXXXYZubm5XHbZZRQUFISVcxuwBPg/4O36atf3UYiIHCD29fsodEQhIiKhFBQiIhJKQSEiIqFSEhRmNsTMysxstZlNSLA808xmBMuXmFl23LKbg/YyMytMRT0iIpI6SQdFMG7Ig8D5QF/gSjPrW6vbNcAWdz8G+AVwd7BuX+AKYh/2GAI8tC/jkIiISNNJxRFFf2C1u69x953Ak8DQWn2GAtOD6SLgHDOzoP1Jd//c3f8JrA7uT0REAjOXlzNg8jz6THieAZPnMXN5ebNuPxVB0RNYHze/IWhL2MfddwHbgK4NXBcAMxtjZlEzi27atCkFZYuItHzV301RvrUS54vvpmjOsGg1F7Pdfaq7R9w90r1793SXIyLSLBry3RRNLRVBUQ70jpvvFbQl7GNmGUBH4OMGrisicsCK/w6KhrQ3hVQExVLgWDPrY2YHEbs4PatWn1nAyGB6ODDPYx8JnwVcEbwrqg9wLPBaCmoSEdkv9OiU1aj2ppB0UATXHMYBs4G3gKfcfaWZTTKzi4JufwC6mtlq4EZgQrDuSuAp4E3gb8B/uvvu2tsQETlQjS/MIavd3m8GzWrXlvGFOXWskXoa60lEpIWbubycKbPLqNhaSY9OWYwvzGFYQcL3/YTa17Ge9H0UIiItXPV3U6RLq3nXk4iIpIeCQkREQikoREQklIJCRERCKShERCSUgkJEREIpKEREJJSCQkREQikoREQklIJCRERCKShERCSUgkJEREIpKEREJJSCQkREQikoREQklIJCRERCKShERCSUgkJEREIpKEREJJSCQkREQiUVFGbWxczmmNmq4GfnOvqNDPqsMrORQdshZva8mb1tZivNbHIytYiISNNI9ohiAjDX3Y8F5gbzezGzLsAdwGlAf+COuEC5192PBwqAAWZ2fpL1iIhIiiUbFEOB6cH0dGBYgj6FwBx33+zuW4A5wBB3/8zd5wO4+05gGdAryXpERCTFkg2KI9x9YzD9PnBEgj49gfVx8xuCthpm1gn4FrGjkoTMbIyZRc0sumnTpuSqFhGRBsuor4OZvQQcmWDRrfEz7u5m5o0twMwygD8Dv3b3NXX1c/epwFSASCTS6O2IiMi+qTco3H1wXcvM7AMzO8rdN5rZUcCHCbqVA4Pi5nsBC+LmpwKr3P2XDapYRESaVbKnnmYBI4PpkcCzCfrMBs4zs87BRezzgjbM7C6gI/CjJOsQEZEmkmxQTAbONbNVwOBgHjOLmNnvAdx9M3AnsDS4TXL3zWbWi9jpq77AMjMrMbNrk6xHRERSzNxb3+n+SCTi0Wg03WWIiLQqZlbs7pHGrqdPZouISCgFhYiIhFJQiIhIKAWFiIiEUlCIiEgoBYWIiIRSUIiISCgFhYiIhFJQiIhIKAWFiIiEUlCIiEgoBYWIiIRSUIiISCgFhYiIhFJQiIhIKAWFiIiEUlCIiEgoBYWIiIRSUIiISCgFhYiIhFJQiIhIKAWFiIiESioozKyLmc0xs1XBz8519BsZ9FllZiMTLJ9lZqXJ1CIiIk0j2SOKCcBcdz8WmBvM78XMugB3AKcB/YE74gPFzC4BtidZh4iINJFkg2IoMD2Yng4MS9CnEJjj7pvdfQswBxgCYGYdgBuBu5KsQ0REmkiyQXGEu28Mpt8HjkjQpyewPm5+Q9AGcCdwH/BZfRsyszFmFjWz6KZNm5IoWUREGiOjvg5m9hJwZIJFt8bPuLubmTd0w2aWD3zN3W8ws+z6+rv7VGAqQCQSafB2REQkOfUGhbsPrmuZmX1gZke5+0YzOwr4MEG3cmBQ3HwvYAHwdSBiZmuDOg43swXuPggREWkxkj31NAuofhfTSODZBH1mA+eZWefgIvZ5wGx3/62793D3bOB04B2FhIhIy5NsUEwGzjWzVcDgYB4zi5jZ7wHcfTOxaxFLg9ukoE1ERFoBc299p/sjkYhHo9F0lyEi0qqYWbG7Rxq7nj6ZLSIioRQUIiISSkEhIiKhFBQiIhJKQSEiIqEUFCIiEkpBISIioRQUIiISSkEhIiKhFBQiIhJKQSEiIqEUFCIiEkpBISIioRQUIiISSkEhIiKhFBQiIhJKQSEiIqEUFCIiEkpBISIioRQUIiISSkEhIiKhkgoKM+tiZnPMbFXws3Md/UYGfVaZ2ci49oPMbKqZvWNmb5vZt5OpR0REUi/ZI4oJwFx3PxaYG8zvxcy6AHcApwH9gTviAuVW4EN3Pw7oC/wjyXpERCTFkg2KocD0YHo6MCxBn0JgjrtvdvctwBxgSLBsNPBzAHff4+4fJVmPiIikWLJBcYS7bwym3weOSNCnJ7A+bn4D0NPMOgXzd5rZMjP7i5klWh8AMxtjZlEzi27atCnJskVEpKHqDQoze8nMShPchsb3c3cHvBHbzgB6Aa+4+8nAYuDeujq7+1R3j7h7pHv37o3YjIiIJCOjvg7uPriuZWb2gZkd5e4bzewo4MME3cqBQXHzvYAFwMfAZ8AzQftfgGsaVraIiDSXZE89zQKq38U0Eng2QZ/ZwHlm1jm4iH0eMDs4AvlfvgiRc4A3k6xHRERSLNmgmAyca2argMHBPGYWMbPfA7j7ZuBOYGlwmxS0AdwETDSzN4Crgf9Ksh4REUkxi/1j37pEIhGPRqPpLkNEpFUxs2J3jzR2PX0yW0REQikoREQklIJCRERCKShERCSUgkJEREIpKEREJJSCQkREQikoREQklIJCRERCKShERCSUgkJEREIpKEREJJSCQkREQikoREQklIJCRERCKShERCSUgkJEREIpKEREJJSCQkREQikoREQklIJCRERCKShERCRUUkFhZl3MbI6ZrQp+dq6j38igzyozGxnXfqWZrTCzN8zsb2bWLZl64k2bNo2Kiop6+02cOJF77703VZsVEdnvJHtEMQGY6+7HAnOD+b2YWRfgDuA0oD9wh5l1NrMM4FfAWe5+EvAGMC7Jemo0NChERCRcskExFJgeTE8HhiXoUwjMcffN7r4FmAMMASy4tTczAw4D6v3LbmbtV61aRb9+/cjNzeXuu+8mPz+f/Px88vLyMDOKioqIRqOMGDGC/Px8Kisryc7O5qOPPgIgGo0yaNCgL933I488wvnnn09lZSWTJk3i1FNPJTc3lzFjxuDujd45IiL7g2SD4gh33xhMvw8ckaBPT2B93PwGoKe7VwHfA1YQC4i+wB/q2pCZjTGzKPD67t27ef311yktLWXs2LGUlJRQUlLCkCFD+PGPf8zw4cOJRCI88cQTlJSUkJWVVe8DeeCBB3juueeYOXMmWVlZjBs3jqVLl1JaWkplZSXPPfdcg3aIiMj+pt6gMLOXzKw0wW1ofD+P/cvd4H+7zawdsaAoAHoQO/V0c1393X2qu0eAb1ZVVXHTTTexaNEiOnbsCMCMGTNYtmwZkydPbmgJNR5//HFefPFFioqKyMzMBGD+/Pmcdtpp5OXlMW/ePFauXNno+xUR2R9k1NfB3QfXtczMPjCzo9x9o5kdBXyYoFs5MChuvhewAMgP7v/d4L6eIsE1jgT1vFN9muknP/kJ55xzDpdccgkTJ05k4cKFtG3bNuF6GRkZ7NmzB4AdO3bstSwvL4+SkhI2bNhAnz592LFjB9dffz3RaJTevXszceLEL60jInKgSPbU0yyg+l1MI4FnE/SZDZwXXMDuDJwXtJUDfc2se9DvXOCt+jZoZj3atGnDVVddxfjx41m2bBlXXnkljz/+ON27d6/pd+ihh/LJJ5/UzGdnZ1NcXAzA008/vdd9FhQU8PDDD3PRRRdRUVFREwrdunVj+/btFBUV1b8nRET2U8kGxWTgXDNbBQwO5jGziJn9HsDdNwN3AkuD26TgwnYF8FNgoZm9QewI478bsM28t99+m/z8fH76059SUFDAe++9x3XXXVdzURtg1KhRjB07tuZi9h133MEPf/hDIpFIwqOO008/nXvvvZcLLriAXbt2cd1115Gbm0thYSGnnnpqkrtJRKT1stb4bp5IJOLRaDTdZYiItCpmVhxc620UfTJbRERCKShERCSUgkJEREIpKEREJJSCQkREQtX7gbv9xczl5UyZXUbF1kp6dMpifGEOwwp6prssEZEW74AIipnLy7n5mRVUVu0GoHxrJTc/swJAYSEiUo8D4tTTlNllNSFRrbJqN1Nml6WpIhGR1uOACIqKrZWNahcRkS8cEEHRo1PiYcbrahcRkS8cEEExvjCHrHZ7j++U1a4t4wtz0lSRiEjrcUBczK6+YK13PYmINN4BERQQCwsFg4hI4x0Qp55ERGTfKShERCSUgkJEREIpKEREJJSCQkREQrXKr0I1s03Ae41crRvwUROUkyzV1XgttTbV1Xgttbb9ta6vuHv3xq7UKoNiX5hZdF++K7apqa7Ga6m1qa7Ga6m1qa696dSTiIiEUlCIiEioAykopqa7gDqorsZrqbWprsZrqbWprjgHzDUKERHZNwfSEYWIiOwDBYWIiIRz91ZxA4YAZcBqYEKC5V8B5gJvAAuAXnHL7gZKg9vlce0G/Ax4B3gL+EFc+6+Dbb0BnNxC6hoEbANKgtvtzVzXorhtVwAzG7u/0lBbuvfZOcCyYNsvA8cE7ZnAjGBbS4DsFlLXKGBT3P66Ng2/y7OD2kqB6UBGC3ld1lVXY55jjwIfAqV1LK/zMQIjgVXBbWRc+ynAimCdX/PFJYUuwJyg/xygc9jvMvT3vK8rNucNaAu8C3wVOAh4Hehbq89fqnde8Av9YzB9QbCTMoD2wFLgsGDZvwOPA22C+cODn98EXgx+af8GLGkhdQ0CnkvX/qq1/tPAdxuzv9JUW1r3GbGwPyGYvh6YFjf9u2D6CmBGC6lrFPBAul6XxM5yrAeOC/pNAq5J9+uynroa9BwL+p4BnEzdQZHwMRL7o78m+Nk5mO4cLHst6GvBuucH7fcQhCQwAbi7ITUmurWWU0/9gdXuvsbddwJPAkNr9ekLzAum58ct7wssdPdd7v4psZQeEiz7HjDJ3fcAuPuHQftQ4HGPeRXoZGZHtYC6Gqqp6gLAzA4j9uKaGTQ1dH+lo7aGaqq6nNgfGoCOxI52CNadHkwXAeeYmbWAuhqjKWrrCux093eCfnOAbwfT6XxdhtXVYO6+ENgc0qWux1gIzHH3ze6+Jdj+kGDZYe7+qscS4XFgWNx9VT/Hpse1N1prCYqexNK82oagLd7rwCXB9MXAoWbWNWgfYmaHmFk34Cygd9Dva8DlZhY1sxfN7NhGbC8ddQF83cxeD9pPTFBTU9ZVbRgw193/1Yjtpas2SO8+uxZ4wcw2AFcDk2tvz913ETt10bUF1AXwbTN7w8yKzKz2/m3q2j4CMsys+tPHw+NqTufrMqwuaNhzrCHqqj2sfUOCdoAj3H1jMP0+cMS+FtVagqIhfgycaWbLgTOBcmC3u/8deAF4BfgzsBjYHayTCezw2EfiHyF2/rAl17WM2Fgt/YDf0Pj/mpOtq9qVwbKmksra0r3PbgC+6e69gMeA+5PYfnPU9b/ErpecROy/1ukkp1G1Bf8VXwH8wsxeAz7hy7/jVEhlXal8jjWJoH5P5g5a/A34OjA7bv5m4OaQ/h2ADXUs+xOxFwjA20CfYNqAbcH0w8CVceuUAUelu64E66wFujVXXcF8N+Bj4OC4tu8xZrgAAAIDSURBVAbtr3TUls59BnQH3o1rPxp4M5ieDXw9mM4g9h+rpbuuWv3b1vXca+rfZVz7ecBTjXmeNXddDX2OxS3Ppu5rFAkfI7F/gB6u3S9Y9nZce02/+P0T9Curq6b6bvu0UnPfghfSGqAPX1ycOrFWn258cfH3Z8TO8Vc/2bsG0ycRe8dC9bsVJgOjg+lBwNJg+gL2vqD0Wgup60i+eEdDf2Adif+4NEldQdtYYHqt+2rQ/kpTbWnbZ3wRANUXQK8Bng6m/5O9L2bX9Uenues6Ku5+LwZeTcPrsvrNG5nE3pl0dgt5XdZVV4OeY3HbzqbuoEj4GIldxP4nsQvZnYPpLsGy2hezq//hnMLeF7Pvqaum+m5pD4EGFxr7T+gdYu9muDVomwRcFEwPJ/Y2sHeA3wOZQfvBwJvB7VUgP+4+OwHPE3tr2WKgX9BuwIPBtlYAkRZS1zhgZfDEfxX4RnPWFSxfAAyp1dbg/ZWG2tK6z4j9sV0RbH8B8NW4df5C7C2Nr1W3t4C6fh63v+YDx6fhdTmF2NvCy4Af7cvzrJnrasxz7M/ARqCK2PWEa4j9gzO2vscIjA6eL6uBf49rjxALtHeBB/gitLoSC7RVwEsEwbIvNw3hISIiofani9kiItIEFBQiIhJKQSEiIqEUFCIiEkpBISIioRQUIiISSkEhIiKh/h+BOuEf7cUAAAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "Running Truncated SVD over 22957 words...\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* What clusters together in 2-dimensional embedding space? \n",
        "\n",
        "On normalized plot:\n",
        "\n",
        "`literatura`, `poeta`, `obywatel`\n",
        "\n",
        "On not normalized plot:\n",
        "\n",
        "`śpiewaczka` and `poeta`\n",
        "\n",
        "* What doesn’t cluster together that you might think should have? \n",
        "\n",
        "On normalized plot:\n",
        "\n",
        "I think all of the words should cluster together. E\n",
        "\n",
        "On not normalized plot:\n",
        "\n",
        "I think all of the words should cluster together. Especially `literatura` should cluster with `śpiewczka`, `poeta` and `sztuka`.\n",
        "\n",
        "* Is normalization necessary?\n",
        "\n",
        "I think normalization is necessary because if the data set contains an unbalanced number of some words (for example because the data comes from books about nature) then vectors representing these words will have a bigger length. This may result in weird clustering (or lack of clustering) of words."
      ],
      "metadata": {
        "id": "z-rrxcfK2AkY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 2 Prediction-Based Word Vectors**"
      ],
      "metadata": {
        "id": "k0dZBOjK0zwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-n0xrk84o5c",
        "outputId": "660ad714-43b2-490b-e9bd-c10dff466e76"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **a) Reducing dimensionality of Word2Vec Word Embeddings**"
      ],
      "metadata": {
        "id": "rOJorlWv0mVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 2:\n",
        "#################################\n",
        "# Then run the following to load the word2vec vectors into memory. \n",
        "# Note: This might take several minutes.\n",
        "wv_from_bin_pl = KeyedVectors.load(\"/content/drive/My Drive/Natural Language processing/Practical_1/word2vec_100_3_polish.bin\")\n",
        "\n",
        "# -----------------------------------\n",
        "# Run Cell to Load Word Vectors\n",
        "# Note: This may take several minutes\n",
        "# -----------------------------------\n",
        "\n",
        "\n",
        "#################################\n",
        "# TODO: a)\n",
        "def get_matrix_of_vectors(wv_from_bin, required_words):\n",
        "    \"\"\" Put the word2vec vectors into a matrix M.\n",
        "        Param:\n",
        "            wv_from_bin: KeyedVectors object; the 3 million word2vec vectors\n",
        "                         loaded from file\n",
        "        Return:\n",
        "            M: numpy matrix shape (num words, 300) containing the vectors\n",
        "            word2Ind: dictionary mapping each word to its row number in M\n",
        "    \"\"\"\n",
        "    words = list(wv_from_bin.key_to_index.keys())\n",
        "    print(\"Shuffling words ...\")\n",
        "    random.shuffle(words)\n",
        "    words = words[:10000]\n",
        "    print(\"Putting %i words into word2Ind and matrix M...\" % len(words))\n",
        "    word2Ind = {}\n",
        "    M = []\n",
        "    curInd = 0\n",
        "    for w in words:\n",
        "        try:\n",
        "            M.append(wv_from_bin.word_vec(w))\n",
        "            word2Ind[w] = curInd\n",
        "            curInd += 1\n",
        "        except KeyError:\n",
        "            continue\n",
        "    for w in required_words:\n",
        "        try:\n",
        "            M.append(wv_from_bin.word_vec(w))\n",
        "            word2Ind[w] = curInd\n",
        "            curInd += 1\n",
        "        except KeyError:\n",
        "            continue\n",
        "    M = np.stack(M)\n",
        "    print(\"Done.\")\n",
        "    return M, word2Ind\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# Run Cell to Reduce 300-Dimensinal Word Embeddings to k Dimensions\n",
        "# Note: This may take several minutes\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "#################################\n",
        "# TODO: a)\n",
        "M, word2Ind = get_matrix_of_vectors(wv_from_bin_pl, words)\n",
        "M_reduced = reduce_to_k_dim(M, k=2)\n",
        "\n",
        "words = [\n",
        "    \"sztuka\", \"śpiewaczka\", \"literatura\", \"poeta\", \"obywatel\"]\n",
        "plot_embeddings(M_reduced, word2Ind, words)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "Rld-BzoV02I7",
        "outputId": "75b208b1-b217-4477-8898-b52a91620542"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shuffling words ...\n",
            "Putting 10000 words into word2Ind and matrix M...\n",
            "Done.\n",
            "Running Truncated SVD over 10005 words...\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* What clusters together in 2-dimensional embedding space? \n",
        "\n",
        "`literatura` and `obywatel`\n",
        "\n",
        "* What doesn’t cluster together that you might think should have? \n",
        "\n",
        "Like I wrote above, I think all words should cluster. Especially `literatura` should cluster with `sztuka` and `poeta`.\n",
        "* How is the plot different from the one generated earlier from the co-occurrence matrix?\n",
        "\n",
        "\n",
        "Words are more scattered."
      ],
      "metadata": {
        "id": "koXs-kDC1xva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **b) Polysemous Words**"
      ],
      "metadata": {
        "id": "mL2iasgF1iip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "# TODO: b)\n",
        "# Polysemous Words\n",
        "print(wv_from_bin_pl.most_similar('komentować'))\n",
        "# Write your polysemous word exploration code here.\n",
        "\n",
        "print(wv_from_bin_pl.most_similar(\"stówa\"))\n",
        "# ------------------\n",
        "\n",
        "#################################"
      ],
      "metadata": {
        "id": "YtoFmnmJ08ki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f49e29f-7c95-4a94-ce16-166d2e6b702d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('relacjonować', 0.8024853467941284), ('przemilczać', 0.7108123898506165), ('opisywać', 0.7035387754440308), ('referować', 0.6902177333831787), ('skomentować', 0.68558669090271), ('parodiować', 0.6824942231178284), ('wykpiwać', 0.6747420430183411), ('krytykować', 0.6696772575378418), ('przytaczać', 0.6656436920166016), ('inscenizować', 0.6649641394615173)]\n",
            "[('słowa', 0.6893048286437988), ('cent', 0.6367954015731812), ('słowo', 0.6246823072433472), ('stówka', 0.6103435158729553), ('słówko', 0.608944833278656), ('pens', 0.5825462937355042), ('tów', 0.5744858980178833), ('wers', 0.573552668094635), ('centym', 0.5726915597915649), ('komunał', 0.5709105730056763)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:783: RuntimeWarning: invalid value encountered in true_divide\n",
            "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Answer:**\n",
        "`'comment'`\n",
        "\n",
        "`Comment - e.g. a football match`\n",
        "`Comment - e.g. to criticize`\n",
        "\n",
        "example:\n",
        "\n",
        "Dariusz Szpakowski comments on the Poland - Italy match.\n",
        "\n",
        "Mom commented on her son's unpleasant behavior at the table.\n",
        "\n",
        "In the sentences above, the word comment has different meanings. In the former, the meaning is literal, in the latter, commenting is understood as criticizing.\n",
        "\n",
        "# **Why do you think many of the polysemous words you tried didn’t work?**\n",
        "\n",
        "Many of the words that I tried were not polyesmous because the Polish language is so rich that it is difficult to find words that have completely different meanings depending on the context. The opposite is in English. There are many more of these types of words."
      ],
      "metadata": {
        "id": "1luFRPuZx_bE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **c) Synonyms & Antonyms**"
      ],
      "metadata": {
        "id": "rKfJB74ky22f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "# TODO: c)\n",
        "# Synonyms & Antonyms\n",
        "w1 = \"ubierać\"\n",
        "w2 = \"zakładać\"\n",
        "w3 = \"rozbierać\"\n",
        "w1_w2_dist = wv_from_bin_pl.distance(w1, w2)\n",
        "w1_w3_dist = wv_from_bin_pl.distance(w1, w3)\n",
        "\n",
        "print(\"Synonyms {}, {} have cosine distance: {}\".format(w1, w2, w1_w2_dist))\n",
        "print(\"Antonyms {}, {} have cosine distance: {}\".format(w1, w3, w1_w3_dist))\n",
        "# Write your synonym & antonym exploration code here.\n",
        "\n",
        "w1 = \"radosny\"\n",
        "w2 = \"pogodny\"\n",
        "w3 = \"smutny\"\n",
        "w1_w2_dist = wv_from_bin_pl.distance(w1, w2)\n",
        "w1_w3_dist = wv_from_bin_pl.distance(w1, w3)\n",
        "\n",
        "print(\"Synonyms {}, {} have cosine distance: {}\".format(w1, w2, w1_w2_dist))\n",
        "print(\"Antonyms {}, {} have cosine distance: {}\".format(w1, w3, w1_w3_dist))\n",
        "\n",
        "#################################"
      ],
      "metadata": {
        "id": "Ieffbzbk0-lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38792b04-3613-43a0-fa6f-5540a6a22ca9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synonyms ubierać, zakładać have cosine distance: 0.7278538644313812\n",
            "Antonyms ubierać, rozbierać have cosine distance: 0.26450175046920776\n",
            "Synonyms radosny, pogodny have cosine distance: 0.3306429386138916\n",
            "Antonyms radosny, smutny have cosine distance: 0.347899854183197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Why this counter intuitive result may have happened?**\n",
        "It seems to me that the word `zakładać` is rarely used in the context of `ubrania`."
      ],
      "metadata": {
        "id": "r2vXZFZpyjIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **d) Finding Analogies**"
      ],
      "metadata": {
        "id": "Q5qAvEQHzBdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: d)\n",
        "# Solving Analogies with Word Vectors\n",
        "# ------------------\n",
        "pprint.pprint(wv_from_bin_pl.most_similar(\n",
        "    positive=[\"kot\", \"lwica\"], negative=[\"lew\"]))\n",
        "# ------------------\n",
        "# Write your analogy exploration code here.\n",
        "pprint.pprint(wv_from_bin_pl.most_similar(\n",
        "    positive=[\"syn\", \"kobieta\"], negative=[\"mezczyzna\"]))\n",
        "\n",
        "\n",
        "#################################"
      ],
      "metadata": {
        "id": "XNyvhS5d1Cbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1334a11f-f4e5-4963-a5a5-a0bd0f4a9766"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('kocica', 0.7683546543121338),\n",
            " ('kotka', 0.7580625414848328),\n",
            " ('suczka', 0.7510557770729065),\n",
            " ('fretka', 0.7507363557815552),\n",
            " ('zwierzątko', 0.7293815016746521),\n",
            " ('kociak', 0.7208428978919983),\n",
            " ('kocię', 0.7118603587150574),\n",
            " ('łasica', 0.7073625326156616),\n",
            " ('małpka', 0.7022215127944946),\n",
            " ('zwierzak', 0.7007642388343811)]\n",
            "[('córka', 0.6928777098655701),\n",
            " ('dziecko', 0.6763085722923279),\n",
            " ('matka', 0.6552439332008362),\n",
            " ('żona', 0.6547046899795532),\n",
            " ('siostra', 0.6358523368835449),\n",
            " ('mąż', 0.6058387160301208),\n",
            " ('dziewczę', 0.6008315086364746),\n",
            " ('rodzic', 0.5781418681144714),\n",
            " ('ojciec', 0.5779308676719666),\n",
            " ('rodzeństwo', 0.5768202543258667)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:783: RuntimeWarning: invalid value encountered in true_divide\n",
            "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Answer**\n",
        "`lew: kot :: lwica: kocica`"
      ],
      "metadata": {
        "id": "kAE7LcPY4cVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **e) Incorrect Analogies**"
      ],
      "metadata": {
        "id": "LKFuN12ezHmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "# TODO: e)\n",
        "# Incorrect Analogy\n",
        "# ------------------\n",
        "pprint.pprint(wv_from_bin_pl.most_similar(\n",
        "    positive=[\"jeleń\", \"lwica\"], negative=[\"lew\"]))\n",
        "\n",
        "# ------------------"
      ],
      "metadata": {
        "id": "cI3V1HDj1D5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e3d286b-9f98-4268-bbd1-b67009983ef2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('sarenka', 0.733302891254425),\n",
            " ('łasica', 0.726658046245575),\n",
            " ('kocica', 0.7265701293945312),\n",
            " ('gazela', 0.7262505292892456),\n",
            " ('tygrysica', 0.715373694896698),\n",
            " ('wilczyca', 0.7132043242454529),\n",
            " ('antylopa', 0.6952416300773621),\n",
            " ('słonica', 0.6938884854316711),\n",
            " ('kojot', 0.6847917437553406),\n",
            " ('klacz', 0.6847697496414185)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:783: RuntimeWarning: invalid value encountered in true_divide\n",
            "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Answer**\n",
        "\n",
        "`lew: jeleń :: lwica: sarenka`\n",
        "\n",
        "Should `sarna` instead of `sarenka`."
      ],
      "metadata": {
        "id": "YcDL2h-p4iHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **f) Guided Analysis of Bias in Word Vectors**"
      ],
      "metadata": {
        "id": "h_Qckp23zLH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "# TODO: f)\n",
        "# Guided Analysis of Bias in Word Vectors\n",
        "# Here `positive` indicates the list of words to be similar to and \n",
        "# `negative` indicates the list of words to be most dissimilar from.\n",
        "# ------------------\n",
        "pprint.pprint(wv_from_bin_pl.most_similar(\n",
        "    positive=['kobieta', 'szefowa'], negative=['mezczyzna']))\n",
        "print()\n",
        "pprint.pprint(wv_from_bin_pl.most_similar(\n",
        "    positive=['mezczyzna', 'szef'], negative=['kobieta']))"
      ],
      "metadata": {
        "id": "gNXniHyW1FW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "641edc16-ecda-4215-fa0a-eeff3579cd07"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('pracowniczka', 0.643110454082489),\n",
            " ('praktykantka', 0.6401199102401733),\n",
            " ('dyrektorka', 0.6252585649490356),\n",
            " ('prezeska', 0.6222735047340393),\n",
            " ('koordynatorka', 0.6162452697753906),\n",
            " ('policjantka', 0.6106235980987549),\n",
            " ('konsultantka', 0.6103208065032959),\n",
            " ('kierowniczka', 0.6071678400039673),\n",
            " ('pielęgniarka', 0.6062616109848022),\n",
            " ('lekarka', 0.605736494064331)]\n",
            "\n",
            "[('zastępca', 0.6033658981323242),\n",
            " ('pulkownik', 0.5758262276649475),\n",
            " ('cielem', 0.5458890199661255),\n",
            " ('zastepca', 0.5408223867416382),\n",
            " ('usilowaly', 0.5374375581741333),\n",
            " ('czlonkiem', 0.5349616408348083),\n",
            " ('obowiazków', 0.5332584381103516),\n",
            " ('opucil', 0.5332545638084412),\n",
            " ('komendant', 0.532918393611908),\n",
            " ('obowiazani', 0.5302093029022217)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:783: RuntimeWarning: invalid value encountered in true_divide\n",
            "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What do you find in the top 10?**\n",
        "\n",
        "Answer above"
      ],
      "metadata": {
        "id": "VZ6rmust2kDt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **g) Independent Analysis of Bias in Word Vectors**"
      ],
      "metadata": {
        "id": "0Vzxp-Y1zRT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "# TODO: g)\n",
        "pprint.pprint(wv_from_bin_pl.most_similar(\n",
        "    positive=['hindus', 'praca'], negative=['niemiec']))\n",
        "print()\n",
        "\n",
        "pprint.pprint(wv_from_bin_pl.most_similar(\n",
        "    positive=['niemiec', 'praca'], negative=['hindus']))\n",
        "print()\n",
        "# ------------------"
      ],
      "metadata": {
        "id": "Ri1_CwxZ1HVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7692686e-6c46-4d1f-abd9-496c03fca33d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('bramin', 0.5531176924705505),\n",
            " ('profesja', 0.5462596416473389),\n",
            " ('sadhu', 0.5459310412406921),\n",
            " ('praktyk', 0.5381325483322144),\n",
            " ('medytacja', 0.5359070897102356),\n",
            " ('jogini', 0.5339097380638123),\n",
            " ('jog', 0.5323072671890259),\n",
            " ('zazen', 0.5295499563217163),\n",
            " ('swami', 0.5285502672195435),\n",
            " ('svatmarama', 0.5278098583221436)]\n",
            "\n",
            "[('działalność', 0.5820961594581604),\n",
            " ('prace', 0.5648640394210815),\n",
            " ('akcja', 0.5497881174087524),\n",
            " ('naprawa', 0.53857421875),\n",
            " ('decyzja', 0.5347055196762085),\n",
            " ('robota', 0.523947536945343),\n",
            " ('odbudowa', 0.521183967590332),\n",
            " ('inwestycja', 0.5211167931556702),\n",
            " ('planowanie', 0.5165292024612427),\n",
            " ('operacja', 0.5140879154205322)]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:783: RuntimeWarning: invalid value encountered in true_divide\n",
            "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Briefly explain the example of bias that you discover.**\n",
        "Bias in terms of different nationalities and attitudes to work."
      ],
      "metadata": {
        "id": "q1qBm6Lm2o8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **h) The source of bias in word vectors**\n",
        "The bias manifests itself in the fact that words close to `German` and `work`, as well as distant from `Hindu` are, for example:\n",
        "`działalność`, `odbudowa`, `naprawa`, `akcja`, `inwestycja`, `planowanie` - and create a German as a proactive worker (plans, repairs, invests, runs a business)\n",
        "\n",
        "On the other hand, words close to the `Hindu` and `work` and distant to the `German` are:\n",
        "\n",
        "`Bramin`, `medytacja`, `sadhu`, `zazen` - words used with religion and clergy. So they create a Hindu as a person working mainly on himself (meditates, is a priest, etc.), and less treats work as a way to earn money."
      ],
      "metadata": {
        "id": "hwG_NJ9_3BAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **i) English versus Polish**"
      ],
      "metadata": {
        "id": "ygbR232Z1JPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "wv_from_bin = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0uxvjvQ5r6B",
        "outputId": "856ecffe-8c6e-4d27-90a3-e719ba356e6f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_word2vec():\n",
        "    \"\"\" Load Word2Vec Vectors\n",
        "        Return:\n",
        "            wv_from_bin: All 3 million embeddings, each lengh 300\n",
        "    \"\"\"\n",
        "\n",
        "    vocab = list(wv_from_bin.key_to_index.keys())\n",
        "    print(\"Loaded vocab size %i\" % len(vocab))\n",
        "    return wv_from_bin\n",
        "\n",
        "wv_from_bin = load_word2vec()"
      ],
      "metadata": {
        "id": "oRrv_HCmebGX",
        "outputId": "6b872dca-7dd6-4adb-9250-b6eb8dd613c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded vocab size 3000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **b) Polysemous Words**"
      ],
      "metadata": {
        "id": "csASHSeozXg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "# TODO: b)\n",
        "# Polysemous Words\n",
        "print(wv_from_bin.most_similar('bank'))\n",
        "# Write your polysemous word exploration code here.\n",
        "\n",
        "# ------------------"
      ],
      "metadata": {
        "id": "tRXTqfoBmVeX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96ab175e-c088-48f6-ec22-c02d01decb53"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('banks', 0.7440759539604187), ('banking', 0.690161406993866), ('Bank', 0.6698698401451111), ('lender', 0.6342284679412842), ('banker', 0.6092953085899353), ('depositors', 0.6031531691551208), ('mortgage_lender', 0.5797975659370422), ('depositor', 0.5716427564620972), ('BofA', 0.5714625120162964), ('Citibank', 0.5589520335197449)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Answer**\n",
        "\n",
        "`Bank` - diffrent meanings.\n",
        "\n",
        "bank as a verb (składać pieniądze)\n",
        "\n",
        "banking as a noun (bankowość)\n",
        "etc."
      ],
      "metadata": {
        "id": "cYGS3K7Nai3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **c) Synonyms & Antonyms**"
      ],
      "metadata": {
        "id": "DLbVF8dizb-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "# TODO: c)\n",
        "# Synonyms & Antonyms\n",
        "w1 = \"rich\"\n",
        "w2 = \"opulent\"\n",
        "w3 = \"poor\"\n",
        "w1_w2_dist = wv_from_bin.distance(w1, w2)\n",
        "w1_w3_dist = wv_from_bin.distance(w1, w3)\n",
        "\n",
        "print(\"Synonyms {}, {} have cosine distance: {}\".format(w1, w2, w1_w2_dist))\n",
        "print(\"Antonyms {}, {} have cosine distance: {}\".format(w1, w3, w1_w3_dist))\n",
        "# Write your synonym & antonym exploration code here.\n",
        "\n",
        "#################################"
      ],
      "metadata": {
        "id": "wOsGBaWG1TCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d137f640-9a91-45b6-bc68-68a5f2eb079e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synonyms rich, opulent have cosine distance: 0.6696735620498657\n",
            "Antonyms rich, poor have cosine distance: 0.627720057964325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Why this counter intuitive result may have happened?**\n",
        "It seems to me that the word `opulent` is rarely used overall so it's distant most of the words."
      ],
      "metadata": {
        "id": "9v4nD1xuiUYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **d) Finding Analogies**"
      ],
      "metadata": {
        "id": "WdP5IpqNzffH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: d)\n",
        "# Solving Analogies with Word Vectors\n",
        "# ------------------\n",
        "pprint.pprint(wv_from_bin.most_similar(\n",
        "    positive=[\"man\", \"waitress\"], negative=[\"waiter\"]))\n",
        "# ------------------\n"
      ],
      "metadata": {
        "id": "4Je12qNn1Wqs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d87ef4b-704a-4fb4-a1b3-1ff0dca91d28"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('woman', 0.773227870464325),\n",
            " ('teenage_girl', 0.6492705345153809),\n",
            " ('girl', 0.6411365270614624),\n",
            " ('teenager', 0.6115584969520569),\n",
            " ('boy', 0.5827294588088989),\n",
            " ('teen_ager', 0.5439349412918091),\n",
            " ('teenaged_girl', 0.5038325190544128),\n",
            " ('girlfriend', 0.5008701682090759),\n",
            " ('Robbery_suspect', 0.4987116754055023),\n",
            " ('Prison_escapee', 0.4952958822250366)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Answer:**\n",
        "\n",
        "`man: waiter :: woman : waitress`"
      ],
      "metadata": {
        "id": "1knq_u75fnRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **e) Incorrect Analogies**"
      ],
      "metadata": {
        "id": "Ys4BakOszpDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "# TODO: e)\n",
        "# Incorrect Analogy\n",
        "# ------------------\n",
        "pprint.pprint(wv_from_bin.most_similar(\n",
        "    positive=[\"sleep\", \"kitchen\"], negative=[\"bed\"]))\n",
        "\n",
        "# ------------------\n"
      ],
      "metadata": {
        "id": "aqI_J3BI1YFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd16fd0e-2420-4179-93c3-b6c8f55807f2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('kitchens', 0.5266509056091309),\n",
            " ('cooking', 0.49796661734580994),\n",
            " ('healthful_meals', 0.47584229707717896),\n",
            " ('cooks', 0.4682634472846985),\n",
            " ('Healthful_eating', 0.46467867493629456),\n",
            " ('mealtime', 0.46205735206604004),\n",
            " ('bathroom', 0.4584217369556427),\n",
            " ('stovetops', 0.4533143937587738),\n",
            " ('cook', 0.45076462626457214),\n",
            " ('cook_nutritious_meals', 0.43667396903038025)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Answer:**\n",
        "\n",
        "`Cooking` should be 1st."
      ],
      "metadata": {
        "id": "hbXHDRrrfzR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **f) Guided Analysis of Bias in Word Vectors**"
      ],
      "metadata": {
        "id": "A9Q5zTfEzsmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "# TODO: f)\n",
        "# Guided Analysis of Bias in Word Vectors\n",
        "# Here `positive` indicates the list of words to be similar to and \n",
        "# `negative` indicates the list of words to be most dissimilar from.\n",
        "# ------------------\n",
        "pprint.pprint(wv_from_bin.most_similar(\n",
        "    positive=['woman', 'science'], negative=['man']))\n",
        "print()\n",
        "pprint.pprint(wv_from_bin.most_similar(\n",
        "    positive=['man', 'science'], negative=['woman']))"
      ],
      "metadata": {
        "id": "PwEQnB3h1eU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d40dd418-7813-45b9-f72b-19081307c934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('biology', 0.5811161994934082),\n",
            " ('sciences', 0.5771055221557617),\n",
            " ('faith_Jezierski', 0.5717575550079346),\n",
            " ('Hilal_Khashan_professor', 0.5432188510894775),\n",
            " ('scientific', 0.5337136387825012),\n",
            " ('professor_Burdett_Loomis', 0.5317376255989075),\n",
            " ('DuPont_http://www.dupont.com', 0.5166647434234619),\n",
            " ('arts_humanities', 0.5114614367485046),\n",
            " ('Science', 0.5096142888069153),\n",
            " ('developmental_psychology', 0.5088647603988647)]\n",
            "\n",
            "[('faith_Jezierski', 0.5785573720932007),\n",
            " ('physics_astronomy', 0.5647080540657043),\n",
            " ('sciences', 0.5488621592521667),\n",
            " ('mathematics', 0.5483816266059875),\n",
            " ('scientific', 0.5455992817878723),\n",
            " ('Shlomo_Avineri_professor', 0.5447791814804077),\n",
            " ('biology', 0.537142813205719),\n",
            " ('physics', 0.5347105264663696),\n",
            " ('arithmetic_geometry', 0.5213109850883484),\n",
            " ('impeach_USADA', 0.5136756300926208)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Answer**\n",
        "\n",
        "Sex bias in science (more sciences connected to Math are close to man and far from woman)."
      ],
      "metadata": {
        "id": "qga9PNGGZ2E_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **g) Independent Analysis of Bias in Word Vectors**"
      ],
      "metadata": {
        "id": "yZgTM7PVzx37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "# TODO: g)\n",
        "pprint.pprint(wv_from_bin.most_similar(\n",
        "    positive=['hindu', 'science'], negative=['german']))\n",
        "print()\n",
        "\n",
        "pprint.pprint(wv_from_bin.most_similar(\n",
        "    positive=['german', 'science'], negative=['hindu']))\n",
        "print()\n",
        "# ------------------"
      ],
      "metadata": {
        "id": "58fGdYIz1ggE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0437913d-165c-40ee-e32e-d5a7ef8ca167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('faith_Jezierski', 0.5046392679214478),\n",
            " ('biology', 0.4839395582675934),\n",
            " ('professor_Kent_Redfield', 0.4803318381309509),\n",
            " ('Science', 0.4698144197463989),\n",
            " ('impeach_USADA', 0.46569642424583435),\n",
            " ('scientific', 0.4614698886871338),\n",
            " ('professor_Burdett_Loomis', 0.4595963656902313),\n",
            " ('sciences', 0.4588996171951294),\n",
            " ('Carl_Shepro_professor', 0.4565400183200836),\n",
            " ('Academy_INSA', 0.453952819108963)]\n",
            "\n",
            "[('sciences', 0.44298893213272095),\n",
            " (\"magazine_c't\", 0.4207650125026703),\n",
            " ('bionic_prosthetic_fingers', 0.41890135407447815),\n",
            " ('physics_astronomy', 0.4139890670776367),\n",
            " ('physics', 0.41334205865859985),\n",
            " ('faith_Jezierski', 0.4127029478549957),\n",
            " ('Board_BONU_specialty', 0.4116217792034149),\n",
            " ('mathematics', 0.4094737768173218),\n",
            " ('biology', 0.4091291129589081),\n",
            " ('Forschungszentrum_Jülich', 0.4018917381763458)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Answer**\n",
        "\n",
        "Bias in terms of different nationalities and science."
      ],
      "metadata": {
        "id": "XGaBDeX9O512"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Have you observed any qualitative differences? Answer with up to 7 sentences.**\n",
        "\n",
        "It is harder to find correct analogies in English because many words don't have a distinction for male or female. However, it is easier to find polysemous words in English because the vocabulary isn't as rich as polish. I mean that many words in English have completly diffrent meaning depending on context. For example Bank (the one I found above) or bear, get etc."
      ],
      "metadata": {
        "id": "RifJgkCaPJL-"
      }
    }
  ]
}