# Machine Learning Projects

[![linkedin](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://linkedin.com/in/karol-pustelnik)

Here you can find the projects that I have done so far. Most of them are in PyTorch.

#### Project 1 [Data Noise]

In this task, I verified the impact of the data noise level in neural network training.
I used MLP architecture trained on the MNIST dataset.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/karolpustelnik/Machine_Learning_Projects/blob/main/Karol_Pustelnik_Homework_1_DNN-2.ipynb)



#### Project 2 [Computer Vision - Object detection on MNIST]

In this task, I solved an object detection training and prediction task using the anchor-based approach. I implemented architecture from RetinaNet.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/karolpustelnik/Machine_Learning_Projects/blob/main/Karol_Pustelnik_Assignment_2_RetinaMNIST_with_rotations-2.ipynb)

#### Project 3 [NLP - LSTM sentiment tagger]

In this task, I implemented LSTM Sentiment Tagger for the imdb reviews dataset.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/karolpustelnik/Machine_Learning_Projects/blob/main/Karol_Pustelnik_Homework_RNN_student_version_4.ipynb)

#### Project 4 [Computer Vision - Single Shot MultiBox Detector on PennFudan dataset]

In this task, I implemented architecture from SSD paper to detect people on images (PennFudan dataset)

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/karolpustelnik/Machine_Learning_Projects/blob/main/KP_SSD_on_PennFudan_Problem1_(1)-2.ipynb)

#### Project 5 [Solutions to NLP course MIMUW]

Assignment 1 [Word Vectors]

[![github](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/karolpustelnik/Machine_Learning_Projects/tree/main/NLP/Practical_1)

Assignment 2 [word2vec Algorithm]

[![github](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/karolpustelnik/Machine_Learning_Projects/tree/main/NLP/Practical_2)

Assignment 3 [Neural Machine Translation]

[![github](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/karolpustelnik/Machine_Learning_Projects/tree/main/NLP/Practical_3)

Assignment 4 [Self-Attention, Transformers, Pretraining]

[![github](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/karolpustelnik/Machine_Learning_Projects/tree/main/NLP/Practical_4)

#### Project 5 [Active Learning]

In this project, I implement diffrent strategies for batch selection that leads to the best increase in model performance.


#### Project 4 [Simulation in Pybullet]

In this simple simulation, I add four cubes in random places within the reach of the robot. I wrote an algorithm to get all the cubes close to the (x=0, y=0, z=-0.1) point.

[![github](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/karolpustelnik/Machine_Learning_Projects/tree/main/Robot%20Control/simulation_pybullet)


#### Project 5 [Simulation in Pybullet - working with colours]
In this project I: 
- wrote a program that estimates how long (number of simulation steps) the car should drive forward to be near the target (red ball).
- wrote a program that finds the ball and drive close to it without moving it. The ball is placed randomly in [-3, -3] x [3,3] square, but not too close to [0, 0, 0] (more then 1 m away).
- wrote a program that moves Ball through gate. Ball is located randomly in [1, -1] x [2, 1] rectangle. Car starts in the [0, 0] point. Gate consists of two large blue cylinders in [-2, -1], and [-2, 1] points.

[![github](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/karolpustelnik/Machine_Learning_Projects/tree/main/Robot%20Control/working_with_colours)

#### Project 5 [Programming Robot in Reality]

In this project I programmed a car to do specific tasks such as:
- recognizing ARUCO markers and driving close to them in a specific way,
- picking specific baskets based on colour and moving them to specific location.

I used a real car that I was able to control through wifi.

[![github](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/karolpustelnik/Machine_Learning_Projects/tree/main/Robot%20Control/robot_in_reality)

Below you can find videos of robot performing various tasks:

Moving green basket to specific aruco marker:

[![youtube](https://img.shields.io/badge/YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://youtu.be/2H-OtnuCIMw)

Moving red basket to specific aruco marker:

[![youtube](https://img.shields.io/badge/YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://youtu.be/r0SvsmTElKw)

Driving to aruco markers along their axis:

[![youtube](https://img.shields.io/badge/YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://youtu.be/0XYtlJRBRK8)

Driving to aruco markers along their axis in specific order:

[![youtube](https://img.shields.io/badge/YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://youtu.be/dfY6TrEfoJQ)



